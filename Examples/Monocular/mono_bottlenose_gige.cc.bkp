/**
* This file is part of ORB-SLAM3
*
* Copyright (C) 2017-2021 Carlos Campos, Richard Elvira, Juan J. Gómez Rodríguez, José M.M. Montiel and Juan D. Tardós, University of Zaragoza.
* Copyright (C) 2014-2016 Raúl Mur-Artal, José M.M. Montiel and Juan D. Tardós, University of Zaragoza.
*
* ORB-SLAM3 is free software: you can redistribute it and/or modify it under the terms of the GNU General Public
* License as published by the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM3 is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even
* the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License along with ORB-SLAM3.
* If not, see <http://www.gnu.org/licenses/>.
*/

#include<iostream>
#include<algorithm>
#include<fstream>
#include<chrono>

#include<opencv2/core/core.hpp>

#include<System.h>

#include <cassert>
#include <cstdlib>
#include <cstdio>
#include <filesystem>

#include <iostream>
#include <list>

#include <PvSampleUtils.h>
#include <PvDevice.h>
#include <PvDeviceGEV.h>
#include <PvStream.h>
#include <PvStreamGEV.h>
#include <PvBuffer.h>
#include <opencv2/opencv.hpp>
#include <PvConfigurationWriter.h>

//#include <PvTypes.h>
//#include <PvGenInteger.h>

using namespace std;
using namespace cv;

void LoadImages(const string &strImagePath, const string &strPathTimes,
                vector<string> &vstrImages, vector<double> &vTimeStamps);

namespace fs = std::filesystem;

typedef std::list<PvBuffer *> BufferList;

PV_INIT_SIGNAL_HANDLER();

#define BUFFER_COUNT ( 16 )

///
/// Function Prototypes
///
PvDevice *ConnectToDevice( const PvString &aConnectionID );
PvStream *OpenStream( const PvString &aConnectionID );
void ConfigureStream( PvDevice *aDevice, PvStream *aStream );
void CreateStreamBuffers( PvDevice *aDevice, PvStream *aStream, BufferList *aBufferList );
void AcquireImages( PvDevice *aDevice, PvStream *aStream );
void FreeStreamBuffers( BufferList *aBufferList );

/// Global variables
int gExposure;
int gGain;
char*gDirname;

float gWbRed, gWbGreen, gWbBlue;

void SavePair( PvBuffer *aBuffer ) {
  static int count = 0;
  assert(aBuffer->GetMultiPartContainer()->GetPartCount() == 2);
  IPvImage *img0 = aBuffer->GetMultiPartContainer()->GetPart(0)->GetImage();
  IPvImage *img1 = aBuffer->GetMultiPartContainer()->GetPart(1)->GetImage();
  // Note images are YUVY
  Mat leftIn(img0->GetHeight(), img0->GetWidth(), CV_8UC2, img0->GetDataPointer());
  Mat rightIn(img1->GetHeight(), img1->GetWidth(), CV_8UC2, img1->GetDataPointer());
  // Convert to BGR (standard OpenCV format)

  Mat left, right;
  cvtColor(leftIn, left, COLOR_YUV2BGR_YUYV);
  cvtColor(rightIn, right, COLOR_YUV2BGR_YUYV);

  // Save to disk
  stringstream s;
  s << count++;
  string fname_left = string(gDirname) + "/left_" + s.str() + ".png";
  string fname_right = string(gDirname) + "/right_" + s.str() + ".png";
  imwrite(fname_left, left);
  imwrite(fname_right, right);
}

void Saveimg( PvBuffer *aBuffer ) {
  static int count = 0;
  IPvImage *img0 = aBuffer->GetImage();
  
  // Note images are YUVY
  Mat leftIn(img0->GetHeight(), img0->GetWidth(), CV_8UC2, img0->GetDataPointer());
  
  // Convert to BGR (standard OpenCV format)
  Mat left, right;
  cvtColor(leftIn, left, COLOR_YUV2BGR_YUYV);

  // Save to disk
  stringstream s;
  s << count++;
  string fname_left = string(gDirname) + "/left_" + s.str() + ".png";
  
  imwrite(fname_left, left);
}

PvDevice *ConnectToDevice( const PvString &aConnectionID )
{
  PvDevice *lDevice;
  PvResult lResult;

  // Connect to the Bottlenose camera
  cout << "Connecting to device." << endl;
  lDevice = PvDevice::CreateAndConnect( aConnectionID, &lResult );
  if ( lDevice == nullptr )
  {
    cout << "Unable to connect to device: "
         << lResult.GetCodeString().GetAscii()
         << " ("
         << lResult.GetDescription().GetAscii()
         << ")" << endl;
  }


  return lDevice;
}

PvStream *OpenStream( const PvString &aConnectionID )
{
  PvStream *lStream;
  PvResult lResult;

  // Open stream to the Bottlenose camera
  cout << "Opening stream from device." << endl;
  lStream = PvStream::CreateAndOpen( aConnectionID, &lResult );
  if ( lStream == nullptr )
  {
    cout << "Unable to stream from device. "
         << lResult.GetCodeString().GetAscii()
         << " ("
         << lResult.GetDescription().GetAscii()
         << ")"
         << endl;
  }

  return lStream;
}

void ConfigureStream( PvDevice *aDevice, PvStream *aStream )
{
  // If this is a GigE Vision device, configure GigE Vision specific streaming parameters
  PvDeviceGEV* lDeviceGEV = dynamic_cast<PvDeviceGEV *>( aDevice );
  if ( lDeviceGEV != nullptr )
  {
    PvStreamGEV *lStreamGEV = static_cast<PvStreamGEV *>( aStream );

    // Negotiate packet size
    lDeviceGEV->NegotiatePacketSize();

    // Configure device streaming destination
    lDeviceGEV->SetStreamDestination( lStreamGEV->GetLocalIPAddress(), lStreamGEV->GetLocalPort() );

    uint32_t paramcount;
    PvGenParameterArray *lStreamParams = lStreamGEV->GetParameters();
    paramcount = lStreamParams->GetCount();
    cout << "paramcount: "<< paramcount << endl;

    // Tweak GEV timeouts to avoid ABORT and TIMEOUTPvGenInteger *lResetOnIdle = dynamic_cast<PvGenInteger *>(lStreamGEV->GetParameters()->Get("ResetOnIdle"));
    PvGenInteger *lResetOnIdle = dynamic_cast<PvGenInteger *>(lStreamGEV->GetParameters()->Get("ResetOnIdle"));
    assert(lResetOnIdle != nullptr);
    lResetOnIdle->SetValue(0);
    // Avoids MISSING_PACKETS
    PvGenInteger *lRequestTimeout = dynamic_cast<PvGenInteger *>(lStreamGEV->GetParameters()->Get("RequestTimeout"));
    assert(lRequestTimeout != nullptr);
    lRequestTimeout->SetValue(100000);

    // Force multi-part transmission, this enables stereo image transfer on Bottlenose
    PvGenBoolean *lMultipart = dynamic_cast<PvGenBoolean *>( lDeviceGEV->GetParameters()->Get( "GevSCCFGMultiPartEnabled" ) );
    assert(lMultipart != nullptr);
    // Configure gain and exposure
    PvGenFloat *lExposure = dynamic_cast<PvGenFloat *>( lDeviceGEV->GetParameters()->Get( "exposure" ) );
    
    // PvGenParameter *lExposure = ( lDeviceGEV->GetParameters()->Get( "exposure" ) );
    assert(lExposure != nullptr);
    // PvGenType aType;
    // lExposure->GetType(aType);
    // cout << "aType: "<< aType << endl;
    double exp;
    PvResult lResult = lExposure->GetValue( exp );
    //cout << "Exposure: " << (exp) << endl;

    PvGenInteger *lGain = dynamic_cast<PvGenInteger *>( lDeviceGEV->GetParameters()->Get( "gainRaw" ) );
    assert(lGain != nullptr);
    PvGenFloat *wbBlue = dynamic_cast<PvGenFloat *>( lDeviceGEV->GetParameters()->Get( "wbBlue" ) );
    assert(wbBlue != nullptr);
    PvGenFloat *wbGreen = dynamic_cast<PvGenFloat *>( lDeviceGEV->GetParameters()->Get( "wbGreen" ) );
    assert(wbGreen != nullptr);
    PvGenFloat *wbRed = dynamic_cast<PvGenFloat *>( lDeviceGEV->GetParameters()->Get( "wbRed" ) );
    assert(wbRed != nullptr);

    assert(wbBlue != nullptr);
    assert(wbGreen != nullptr);
    assert(wbRed != nullptr);
    PvResult res = wbBlue->SetValue(gWbBlue);
    assert(res.IsOK());
    res = wbRed->SetValue(gWbRed);
    assert(res.IsOK());
    res = wbGreen->SetValue(gWbGreen);
    assert(res.IsOK());

    assert(lMultipart != nullptr);
    assert(lExposure != nullptr);
    assert(lGain != nullptr);
    lMultipart->SetValue(true);

    //0.04 is max
    gExposure = 0.01;
    res = lExposure->SetValue(gExposure);
    assert(res.IsOK());
    res = lExposure->SetValue(gExposure);
    assert(res.IsOK());
    res = lExposure->SetValue(gExposure);
    assert(res.IsOK());
    gGain = 950;
    res = lGain->SetValue(gGain);
    assert(res.IsOK());
    res = lGain->SetValue(gGain);
    assert(res.IsOK());
    res = lGain->SetValue(gGain);
    assert(res.IsOK());
  }
}

void CreateStreamBuffers( PvDevice *aDevice, PvStream *aStream, BufferList *aBufferList )
{
  // Reading payload size from device
  uint32_t lSize = aDevice->GetPayloadSize();

  // Use BUFFER_COUNT or the maximum number of buffers, whichever is smaller
  uint32_t lBufferCount = ( aStream->GetQueuedBufferMaximum() < BUFFER_COUNT ) ?
                          aStream->GetQueuedBufferMaximum() :
                          BUFFER_COUNT;

  // Allocate buffers
  for ( uint32_t i = 0; i < lBufferCount; i++ )
  {
    // Create new buffer object
    PvBuffer *lBuffer = new PvBuffer;

    // Have the new buffer object allocate payload memory
    lBuffer->Alloc( static_cast<uint32_t>( lSize ) );

    // Add to external list - used to eventually release the buffers
    aBufferList->push_back( lBuffer );
  }

  // Queue all buffers in the stream
  BufferList::iterator lIt = aBufferList->begin();
  while ( lIt != aBufferList->end() )
  {
    aStream->QueueBuffer( *lIt );
    lIt++;
  }
}

void AcquireImages( PvDevice *aDevice, PvStream *aStream )
{
  // Get device parameters need to control streaming
  PvGenParameterArray *lDeviceParams = aDevice->GetParameters();

  // Map the GenICam AcquisitionStart and AcquisitionStop commands
  PvGenCommand *lStart = dynamic_cast<PvGenCommand *>( lDeviceParams->Get( "AcquisitionStart" ) );
  PvGenCommand *lStop = dynamic_cast<PvGenCommand *>( lDeviceParams->Get( "AcquisitionStop" ) );

  // Get stream parameters
  PvGenParameterArray *lStreamParams = aStream->GetParameters();

  // Map a few GenICam stream stats counters
  PvGenFloat *lFrameRate = dynamic_cast<PvGenFloat *>( lStreamParams->Get( "AcquisitionRate" ) );
  PvGenFloat *lBandwidth = dynamic_cast<PvGenFloat *>( lStreamParams->Get( "Bandwidth" ) );

  // Enable streaming and send the AcquisitionStart command
  cout << "Enabling streaming and sending AcquisitionStart command." << endl;
  aDevice->StreamEnable();
  lStart->Execute();

  char lDoodle[] = "|\\-|-/";
  int lDoodleIndex = 0;
  double lFrameRateVal = 0.0;
  double lBandwidthVal = 0.0;

  // Acquire images until the user instructs us to stop.
  cout << endl << "<press a key to stop streaming>" << endl;
  while ( !PvKbHit() )
  {
    PvBuffer *lBuffer = nullptr;
    PvResult lOperationResult;

    // Retrieve next buffer
    PvResult lResult = aStream->RetrieveBuffer( &lBuffer, &lOperationResult, 1000 );
    if ( lResult.IsOK() )
    {
      if ( lOperationResult.IsOK() )
      {
        //
        // We now have a valid buffer. This is where you would typically process the buffer.
        // -----------------------------------------------------------------------------------------
        // ...

        lFrameRate->GetValue( lFrameRateVal );
        lBandwidth->GetValue( lBandwidthVal );

        cout << fixed << setprecision( 1 );
        cout << lDoodle[ lDoodleIndex ];
        cout << " BlockID: " << uppercase << hex << setfill( '0' ) << setw( 16 ) << lBuffer->GetBlockID();

        switch ( lBuffer->GetPayloadType() )
        {
          case PvPayloadTypeImage:
            cout << "  W: " << dec << lBuffer->GetImage()->GetWidth() << " H: " << lBuffer->GetImage()->GetHeight();
            Saveimg(lBuffer);
            break;

          case PvPayloadTypeChunkData:
            cout << " Chunk Data payload type" << " with " << lBuffer->GetChunkCount() << " chunks";
            break;

          case PvPayloadTypeRawData:
            cout << " Raw Data with " << lBuffer->GetRawData()->GetPayloadLength() << " bytes";
            break;

          case PvPayloadTypeMultiPart:
            cout << " Multi Part with " << lBuffer->GetMultiPartContainer()->GetPartCount() << " parts";
            // Preserve
            SavePair(lBuffer);
            break;

          default:
            cout << " Payload type not supported by this sample";
            break;
        }
        cout << "  " << lFrameRateVal << " FPS  " << ( lBandwidthVal / 1000000.0 ) << " Mb/s   \r";
      }
      else
      {
        // Non OK operational result
        cout << lDoodle[ lDoodleIndex ] << " " << lOperationResult.GetCodeString().GetAscii() << "\r";
      }

      // Re-queue the buffer in the stream object
      aStream->QueueBuffer( lBuffer );
    }
    else
    {
      // Retrieve buffer failure
      cout << lDoodle[ lDoodleIndex ] << " " << lResult.GetCodeString().GetAscii() << "\r";
    }

    ++lDoodleIndex %= 6;
  }

  PvGetChar(); // Flush key buffer for next stop.
  cout << endl << endl;

  // Tell the device to stop sending images.
  cout << "Sending AcquisitionStop command to the device" << endl;
  lStop->Execute();

  // Disable streaming on the device
  cout << "Disable streaming on the controller." << endl;
  aDevice->StreamDisable();

  // Abort all buffers from the stream and dequeue
  cout << "Aborting buffers still in stream" << endl;
  aStream->AbortQueuedBuffers();
  while ( aStream->GetQueuedBufferCount() > 0 )
  {
    PvBuffer *lBuffer = nullptr;
    PvResult lOperationResult;

    aStream->RetrieveBuffer( &lBuffer, &lOperationResult );
  }
}

void FreeStreamBuffers( BufferList *aBufferList )
{
  // Go through the buffer list
  BufferList::iterator lIt = aBufferList->begin();
  while ( lIt != aBufferList->end() )
  {
    delete *lIt;
    lIt++;
  }

  // Clear the buffer list
  aBufferList->clear();
}


int main(int argc, char **argv)
{  
    if(argc < 5)
    {
        cerr << endl << "Usage: ./mono_bottlenose: path_to_vocabulary path_to_settings path_to_sequence_folder_1 path_to_times_file_1 (path_to_image_folder_2 path_to_times_file_2 ... path_to_image_folder_N path_to_times_file_N) (trajectory_file_name)" << endl;
        return 1;
    }
/*********************************************************************************/
PvDevice *lDevice = nullptr;
  PvStream *lStream = nullptr;
  BufferList lBufferList;
/*
  if(argc != 4) {
    cerr << "Usage: " << argv[0] << " <exposure_in_us> <gain> <directory to save stereo pairs>" << endl;
    return 1;
  }
*/
  // User set whitebalance gains
  gWbRed = 0.9;
  gWbGreen = 0.6;
  gWbBlue = 1.0;
  cout << "Chosen white balance (" << gWbRed << ", " << gWbGreen << ", " << gWbBlue << ")" << endl;

  //gExposure = atoi(argv[1]);
  gExposure = 1;
  //gGain = atoi(argv[2]);
  gGain = 1;
  if(gExposure < 0 || gExposure > 100000) {
    cerr << "Exposure must be within [0, 100000] us" << endl;
    return 1;
  }
  if(gGain < 0 || gGain > 978) {
    cerr << "Gain value within [0, 978]" << endl;
    return 1;
  }
  /*if(!fs::is_directory(argv[3])) {
    cerr << "Directory " << argv[3] << " does not exist" << endl;
    return 1;
  }*/
  //gDirname = argv[3];
  gDirname = "./";

  cout << gExposure << " " << gGain << " " << endl;

  PV_SAMPLE_INIT();

  cout << "Acquisition Sample:" << endl << endl;

  PvString lConnectionID;
  if ( PvSelectDevice( &lConnectionID ) )
  {
    lDevice = ConnectToDevice( lConnectionID );
    if ( nullptr != lDevice )
    {
      PvGenInteger *intval = dynamic_cast<PvGenInteger *>( lDevice->GetParameters()->Get("GevSCPSPacketSize"));
      assert(intval != nullptr);
      int64_t val;
      intval->GetValue(val);
      if(val < 8000) {
        cerr << "Warning: Configure your NICs MTU to be at least 8K to have reliable image transfer -> overriding to 8K" << endl;
        PvResult res = intval->SetValue(8000);
        assert(res.IsOK());
      }
      lStream = OpenStream( lConnectionID );
      if ( nullptr != lStream )
      {
        ConfigureStream( lDevice, lStream );
        CreateStreamBuffers( lDevice, lStream, &lBufferList );
        AcquireImages( lDevice, lStream );
        FreeStreamBuffers( &lBufferList );

        // Close the stream
        cout << "Closing stream" << endl;
        lStream->Close();
        PvStream::Free( lStream );
      }

      // Disconnect the device
      cout << "Disconnecting device" << endl;
      lDevice->Disconnect();
      PvDevice::Free( lDevice );
    }
  }

  cout << endl;
  cout << "<press a key to exit>" << endl;
  //PvWaitForKeyPress();

  PV_SAMPLE_TERMINATE();

  //return 0;
  /*********************************************************************************/

    const int num_seq = (argc-3)/2;
    cout << "num_seq = " << num_seq << endl;
    bool bFileName= (((argc-3) % 2) == 1);
    string file_name;
    if (bFileName)
    {
        file_name = string(argv[argc-1]);
        cout << "file name: " << file_name << endl;
    }

    // Load all sequences:
    int seq;
    vector< vector<string> > vstrImageFilenames;
    vector< vector<double> > vTimestampsCam;
    vector<int> nImages;

    vstrImageFilenames.resize(num_seq);
    vTimestampsCam.resize(num_seq);
    nImages.resize(num_seq);

    int tot_images = 0;
    for (seq = 0; seq<num_seq; seq++)
    {
        cout << "Loading images for sequence " << seq << "...";
        LoadImages(string(argv[(2*seq)+3]) + "/cam0/data", string(argv[(2*seq)+4]), vstrImageFilenames[seq], vTimestampsCam[seq]);
        cout << "LOADED!" << endl;

        nImages[seq] = vstrImageFilenames[seq].size();
        tot_images += nImages[seq];
    }

    // Vector for tracking time statistics
    vector<float> vTimesTrack;
    vTimesTrack.resize(tot_images);

    cout << endl << "-------" << endl;
    cout.precision(17);


    int fps = 20;
    float dT = 1.f/fps;
    // Create SLAM system. It initializes all system threads and gets ready to process frames.
    //ORB_SLAM3::System SLAM(argv[1],argv[2],ORB_SLAM3::System::MONOCULAR, false);
    ORB_SLAM3::System SLAM(argv[1],argv[2],ORB_SLAM3::System::MONOCULAR, true, 0, string(argv[3]));
    float imageScale = SLAM.GetImageScale();

    double t_resize = 0.f;
    double t_track = 0.f;

    for (seq = 0; seq<num_seq; seq++)
    {

        // Main loop
        cv::Mat im;
        int proccIm = 0;
        for(int ni=0; ni<nImages[seq]; ni++, proccIm++)
        {

            // Read image from file
            im = cv::imread(vstrImageFilenames[seq][ni],cv::IMREAD_UNCHANGED); //,CV_LOAD_IMAGE_UNCHANGED);
            double tframe = vTimestampsCam[seq][ni];

            if(im.empty())
            {
                cerr << endl << "Failed to load image at: "
                     <<  vstrImageFilenames[seq][ni] << endl;
                return 1;
            }

            if(imageScale != 1.f)
            {
#ifdef REGISTER_TIMES
    #ifdef COMPILEDWITHC11
                std::chrono::steady_clock::time_point t_Start_Resize = std::chrono::steady_clock::now();
    #else
                std::chrono::monotonic_clock::time_point t_Start_Resize = std::chrono::monotonic_clock::now();
    #endif
#endif
                int width = im.cols * imageScale;
                int height = im.rows * imageScale;
                cv::resize(im, im, cv::Size(width, height));
#ifdef REGISTER_TIMES
    #ifdef COMPILEDWITHC11
                std::chrono::steady_clock::time_point t_End_Resize = std::chrono::steady_clock::now();
    #else
                std::chrono::monotonic_clock::time_point t_End_Resize = std::chrono::monotonic_clock::now();
    #endif
                t_resize = std::chrono::duration_cast<std::chrono::duration<double,std::milli> >(t_End_Resize - t_Start_Resize).count();
                SLAM.InsertResizeTime(t_resize);
#endif
            }

    #ifdef COMPILEDWITHC11
            std::chrono::steady_clock::time_point t1 = std::chrono::steady_clock::now();
    #else
            std::chrono::monotonic_clock::time_point t1 = std::chrono::monotonic_clock::now();
    #endif

            // Pass the image to the SLAM system
            // cout << "tframe = " << tframe << endl;
            SLAM.TrackMonocular(im,tframe); // TODO change to monocular_inertial

    #ifdef COMPILEDWITHC11
            std::chrono::steady_clock::time_point t2 = std::chrono::steady_clock::now();
    #else
            std::chrono::monotonic_clock::time_point t2 = std::chrono::monotonic_clock::now();
    #endif

#ifdef REGISTER_TIMES
            t_track = t_resize + std::chrono::duration_cast<std::chrono::duration<double,std::milli> >(t2 - t1).count();
            SLAM.InsertTrackTime(t_track);
#endif

            double ttrack= std::chrono::duration_cast<std::chrono::duration<double> >(t2 - t1).count();

            vTimesTrack[ni]=ttrack;

            // Wait to load the next frame
            double T=0;
            if(ni<nImages[seq]-1)
                T = vTimestampsCam[seq][ni+1]-tframe;
            else if(ni>0)
                T = tframe-vTimestampsCam[seq][ni-1];

            //std::cout << "T: " << T << std::endl;
            //std::cout << "ttrack: " << ttrack << std::endl;

            if(ttrack<T) {
                //std::cout << "usleep: " << (dT-ttrack) << std::endl;
                usleep((T-ttrack)*1e6); // 1e6
            }
        }

        if(seq < num_seq - 1)
        {
            string kf_file_submap =  "./SubMaps/kf_SubMap_" + std::to_string(seq) + ".txt";
            string f_file_submap =  "./SubMaps/f_SubMap_" + std::to_string(seq) + ".txt";
            SLAM.SaveTrajectoryEuRoC(f_file_submap);
            SLAM.SaveKeyFrameTrajectoryEuRoC(kf_file_submap);

            cout << "Changing the dataset" << endl;

            SLAM.ChangeDataset();
        }

    }
    // Stop all threads
    SLAM.Shutdown();

    // Save camera trajectory
    if (bFileName)
    {
        const string kf_file =  "kf_" + string(argv[argc-1]) + ".txt";
        const string f_file =  "f_" + string(argv[argc-1]) + ".txt";
        SLAM.SaveTrajectoryEuRoC(f_file);
        SLAM.SaveKeyFrameTrajectoryEuRoC(kf_file);
    }
    else
    {
        SLAM.SaveTrajectoryEuRoC("CameraTrajectory.txt");
        SLAM.SaveKeyFrameTrajectoryEuRoC("KeyFrameTrajectory.txt");
    }

    return 0;
}

void LoadImages(const string &strImagePath, const string &strPathTimes,
                vector<string> &vstrImages, vector<double> &vTimeStamps)
{
    ifstream fTimes;
    fTimes.open(strPathTimes.c_str());
    vTimeStamps.reserve(5000);
    vstrImages.reserve(5000);
    while(!fTimes.eof())
    {
        string s;
        getline(fTimes,s);
        if(!s.empty())
        {
            stringstream ss;
            ss << s;
            vstrImages.push_back(strImagePath + "/" + ss.str() + ".png");
            double t;
            ss >> t;
            vTimeStamps.push_back(t*1e-9);

        }
    }
}
